## ðŸ¤– AI Content Detector Challenge

This project solves a Daily Coding Challenge inspired by the release of ChatGPT. The goal is to determine if a given string of text was likely generated by AI, based on a set of structural complexity rules.

### **Source**

The challenge originates from freeCodeCamp: [Daily Coding Challenge (November 30, 2025)](https://www.freecodecamp.org/learn/daily-coding-challenge/2025-11-30)

---

### **The Approach That I Used to Solve This Problem**

The solution uses a **rule-based, sequential checking mechanism**. The text is classified as **"AI"** if it meets **any** of the following three rules. The function immediately returns "AI" upon the first rule match, optimizing performance by skipping subsequent checks.

#### **Rules Implemented:**

1.  **Dashes:** Check if the text contains $\ge 2$ hyphens (`-`) using the built-in `count()` method.
2.  **Parentheses Sets:** Check if the text contains $\ge 2$ opening parentheses (`(`) **AND** $\ge 2$ closing parentheses (`)`) to ensure the presence of "two or more sets."
3.  **Long Words:** Identify and count words with 7 or more letters. This requires **pre-processing** the text using the `re.sub()` function to remove all punctuation and non-letter characters, ensuring only pure letters are counted in the word length, as specified by the problem. The final count must be $\ge 3$.

If none of the three criteria are met after all checks, the function returns **"Human"**.

---

### **Complexity Analysis**

The solution has a simple and efficient complexity profile, dominated by the need to traverse the input string or its derived components once.

#### **Time Complexity: $O(N)$**

* The overall time complexity is **linear**, where $N$ is the length of the input string (`text`).
* **Rule 1 & 2 (Dashes and Parentheses):** The `count()` methods are highly efficient, traversing the string once for each character count, making these steps $O(N)$.
* **Rule 3 (Long Words):** This involves two $O(N)$ operations:
    1.  Cleaning the string using the regular expression substitution (`re.sub`).
    2.  Iterating through all the resulting words (which are collectively proportional to $N$) to check their length.

Since the checks are performed sequentially and the most complex step is linear, the final time complexity is **$O(N)$**.

#### **Space Complexity: $O(N)$**

* The space complexity is **linear**, $O(N)$, due to the creation of the **`cleaned_text`** variable. This new string holds a copy of the original text after non-letter characters have been replaced with spaces. In the worst case (where the text contains very little punctuation), the size of this new string is directly proportional to the size of the input string $N$.